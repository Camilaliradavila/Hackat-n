# -*- coding: utf-8 -*-
"""Hackat√≥n4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R0RtrcyJ8xocAYPZOyMh89k7Nup8N_g-
"""

#!pip install streamlit

from PyPDF2 import PdfReader
import os
import glob
import pandas as pd
import re
import tiktoken
from PIL import Image
from io import BytesIO
# import pytesseract
# Specify the path where Tesseract-OCR was installed
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
# from pytesseract import Output
import re
import glob
import os
import PIL.Image
from PIL import Image
#from pdf2image import convert_from_path

# Chat GPT
import tiktoken
from langchain.text_splitter import RecursiveCharacterTextSplitter
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
import chromadb
from openai import OpenAI

import streamlit as st

def pdf_to_text(pdf_path):
    '''
    Objective:
        This functions transforms a pdf to a text where we can apply text information retrieval

    Input:
        pdf_path (str) : The path where the pdf is located, including the pdf name.

    Output:
        It returns the text of the pdf
    '''
    reader   = PdfReader( pdf_path )
    n_pages  = len( reader.pages )
    st.write( f'Number of pages: { n_pages }' )

    try:
        extracted_text = [ reader.pages[ i ].extract_text() for i in range( n_pages ) ]
        st.write( 'Text successfully extracted' )

    except:
        extracted_text = []
        st.write( 'Text not found' )


    combined_text = '\n'.join( extracted_text )


    return combined_text

    def extract_text( combined_text , start_pattern , end_pattern):
    '''
    Objective:
        This function takes a text and extracts the patter indicated by the start_patter and end_patter inputs.

    Input:
        combined_text (str) : The text where we can extract information.

        start_pattern (str) : The starting pattern.

        end_pattern (str) : The ending pattern.
    '''
    start_match   = re.search( start_pattern, combined_text, re.IGNORECASE )
    end_match     = re.search( end_pattern, combined_text[ start_match.end(): ], re.IGNORECASE )

    end_index     = start_match.end() + end_match.start()
    article_text  = combined_text[ start_match.end(): end_index ].strip()

    article_text = article_text.split('\n')

    return article_text

folder_path = 'https://github.com/Camilaliradavila/Hackat-n/tree/664d1d05212f010e41c388f85f39ba974df58111/Literatura'
data_dict = {'Filename': [], 'PDF_text': []}

# for pattern in patterns:
for filename in os.listdir(folder_path):
    file_path = os.path.join(folder_path, filename)

    try:
        file_pdf = pdf_to_text(file_path)

    except:
        print(f'{filename} is not a file')
        continue

    data_dict['Filename'].append(filename)
    data_dict['PDF_text'].append(file_pdf)

final_dataframe = pd.DataFrame(data_dict)

st.dataframe(final_dataframe = pd.DataFrame(data_dict)